{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of questions asked by school students  \n",
    "\n",
    "## Overview\n",
    "\n",
    "This is a report on the analysis of science questions asked by students of Telangana Social Welfare\n",
    "Residential schools, of classes VII to IX to the outreach volunteers of TIFR. The dataset contains a sample of 100 questions picked for this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "\n",
    "A good way to discover patterns in textual data is to classify the data and analyse the classes to find hidden trends. In the given dataset, given that the data contains questions asked by students, my basic intuition was to classify the data acording to the subject or field of science from which the question was asked. For example, the question 'How many stars are in the sky?' can be classified as an Astronomy question, 'Which is the biggest animal in Ocean?' is most certainly a Biology question, so on and so forth. \n",
    "\n",
    "After careful analysis and reading through the entire datatset multiple times to get a general feel of the distribuion of questions, I discovered another underlying criteria for classification - some questions were being asked to fill in gaps in the knowledge of students, for example 'Where do petrol and diesel come from?' or 'Which is the coldest place?'. I categorized these questions as 'Comprehension' type quesions, since they have a single factual answer from the science curriculum being taught to these students. But a good chunk of questions in the dataset were not Comprehension type, but were more exploratory in nature, questions that were clearly rooted in curiosity and application of existing knowledge. I categorized these questions as 'Curiosity' type. \n",
    "\n",
    "This classification criteria could provide a high level view of the scientific temperament and understanding among students. It could also help guage the effectiveness of the current curriculum and teaching methodology being used at these schools. For example, if majority of questions asked by students after a session or class are 'Comprehension' type questions, it would be safe to say that we need to improve or even rethink the teaching strategy or the course content. It could also help point out specific areas of the course that might need improvement - for example, if a lot of Comprehension type questions are from the Biology section, it could indicate that the course material might need tweaking or even that the instructor for that particular session could improve his/her method. \n",
    "\n",
    "An attached pdf document titled 'categorized_questions.pdf' contains the entire dataset classified into Comprehension and Curiosity type questions, as well as into fields of science they belong to. Another file, titled data.tsv contains the same labelled data in a format that's easily readable by machine learning libraries such as pandas, which makes it easy to work with datasets. We can load up this file to get some insight into our newly classified data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imorting libraries to handle the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# importing the dataset\n",
    "dataset = pd.read_csv('data.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at a preview of this classified data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Category</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sun is unique so how can it be seen everyw...</td>\n",
       "      <td>Comprehension</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why do the stars and moon appear only at night?</td>\n",
       "      <td>Comprehension</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the shape that we see inside the moon?</td>\n",
       "      <td>Comprehension</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many stars are in the sky?</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where will the star fall after its period is o...</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How the world become? (i.e. How was the univer...</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>So many universes are there so are there peopl...</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is there anything to control a black hole?</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Do aliens exist?</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>As we are on the Earth. Are there any other pl...</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question       Category      Field\n",
       "0  The sun is unique so how can it be seen everyw...  Comprehension  Astronomy\n",
       "1    Why do the stars and moon appear only at night?  Comprehension  Astronomy\n",
       "2     What is the shape that we see inside the moon?  Comprehension  Astronomy\n",
       "3                     How many stars are in the sky?      Curiosity  Astronomy\n",
       "4  Where will the star fall after its period is o...      Curiosity  Astronomy\n",
       "5  How the world become? (i.e. How was the univer...      Curiosity  Astronomy\n",
       "6  So many universes are there so are there peopl...      Curiosity  Astronomy\n",
       "7         Is there anything to control a black hole?      Curiosity  Astronomy\n",
       "8                                   Do aliens exist?      Curiosity  Astronomy\n",
       "9  As we are on the Earth. Are there any other pl...      Curiosity  Astronomy"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the distribution of labels we assigned to the questions using our classification criterias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 63]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_labels = ['Comprehension', 'Curiosity']\n",
    "category_label_count = []\n",
    "\n",
    "for label in category_labels:\n",
    "    category_label_count.append(dataset['Category'].tolist().count(label))\n",
    "    \n",
    "category_label_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the **majority of questions (63%) are 'Curiosity' type** questions while the remaining (37%) are 'Comprehension' type. This indicates towards a general scietific temperament and curiosity among the students. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier\n",
    "\n",
    "Since the given data is a subset of an extensive dataset containing close to 40K questions asked by students, it is a good idea to train a classfier on a labelled sample data to learn the trends in data and use it to classify the entire dataset, instead of categorizing such a massive dataset by hand, which is inefficent and prone to errors. \n",
    "\n",
    "A common Natural Language Processing algorithm used in classification problems such as these is the 'Bag of Words' method, which breaks down each data point into a set of words that represents it. We then train a classifier to understand the corelations between a set of words and their label, which will enable the classfier to classify any unlabelled data. This strategy of NLP is known as Sentiment Analysis, and is frequently used to classfiy texts such as restaurant or movie reviews into positive or negative reviews. For example, reviews containing the keywords 'bad', 'terrible', 'poor' etc would indicate a negative review, while reviews containing the keywords 'great', 'excellent' etc indicates a positive review. \n",
    "\n",
    "Although it might seem like it, but this classification problem cannot be solved using the sentiment analysis method. It is possible for a human with an acceptable level of scientific knowledge and understanding to identify 'Curiosity' type questions among school students, because of the context he/she has. For example, to classify the question 'Do aliens exist?' as a 'Curiosity' type question, the classifier, human or machine, requires the context about the findings and limitaions of the human knowledge of Astronomy. We know intuitively that this is a curiosity driven question since we have not found any evidence of alien life so far and it is a question that has been asked through the centuries by many brilliant scientists. It is not practical to train a classfier that has such context about all branches of science. Also, it is not useful to try and use historical data to identify the Curiosity type questions, as in the example of the question on extraterrestrial life since science keeps evolving and moving forward, and the very nature of scientific curiosity makes it impossible to predict the direction it will take.  \n",
    "\n",
    "Therefore, as a demonstration of how a classifier might be used to process the sample data, I will create and train a Naive-Bayes Classifier to categorise the questions in the sample into topics or branches of scientific study they belong to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/nitin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# since the dataset is already imported we will proceed to clean the text\n",
    "# import the libraries to clean the text\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# two common and powerful methods to clean the data are\n",
    "# removing stopwords like 'the', 'a' etc\n",
    "# and stemming, which converts words like 'rained', 'raining' etc\n",
    "# to their root 'rain'\n",
    "# import the packages that will do this efficiently\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of how the cleaning process works!\n",
      "\n",
      "Replace all symbols and special characters with spaces since we only want to process words/text:\n",
      "--------------------------------------------------\n",
      "The sun is unique so how can it be seen everywhere on the earth \n",
      "\n",
      "Convert all text to lowercase:\n",
      "--------------------------------------------------\n",
      "the sun is unique so how can it be seen everywhere on the earth \n",
      "\n",
      "Remove stop words and apply stemming:\n",
      "--------------------------------------------------\n",
      "sun uniqu seen everywher earth "
     ]
    }
   ],
   "source": [
    "# save the text into a corpus of cleaned data\n",
    "corpus = []\n",
    "\n",
    "# iterate through all questions and apply text \n",
    "# cleaning operations on each one of them\n",
    "\n",
    "print('An example of how the cleaning process works!\\n')\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    # replace all symbols and special characters with spaces\n",
    "    # since we only want to process words/text\n",
    "    question = re.sub('[^a-zA-Z]', ' ', dataset['Question'][i])\n",
    "    \n",
    "    if i == 0:\n",
    "        print('Replace all symbols and special characters with spaces since we only want to process words/text:')\n",
    "        print(\"-\"*50)\n",
    "        print(question)\n",
    "    \n",
    "    # convert all text to lowercase\n",
    "    question = question.lower()\n",
    "    \n",
    "    if i == 0:\n",
    "        print('\\nConvert all text to lowercase:')\n",
    "        print(\"-\"*50)\n",
    "        print(question)\n",
    "    \n",
    "    # split the text into words to apply stemming to each word\n",
    "    question = question.split()\n",
    "    \n",
    "    # import the stemming package\n",
    "    ps = PorterStemmer()\n",
    "    cleaned_question = []\n",
    "    \n",
    "    # iterate through all the words in the question\n",
    "    for word in question:\n",
    "        \n",
    "        # if word is not an english stopword, save the stemmed\n",
    "        # version of word to cleaned_question\n",
    "        if not word in set(stopwords.words('english')):\n",
    "            cleaned_question.append(ps.stem(word))\n",
    "            \n",
    "    if i == 0:\n",
    "        print('\\nRemove stop words and apply stemming:')\n",
    "        print(\"-\"*50)\n",
    "        [print(i, end=\" \") for i in cleaned_question]\n",
    "    \n",
    "    # append the cleaned text for the question to corpus\n",
    "    corpus.append(cleaned_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500, tokenizer=lambda doc: doc, lowercase=False)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# fitting classifier to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# calculating the accuracy score of the classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I picked the Naive-Bayes classification algorithm to build the classifier because it is the most widely used classificatin algorithm for sentiment analysis and is better suited to work with when the sample size is small, as opposed to the Decision-Tree classifier that tends to overfit to the data and has poor performance with small samples.\n",
    "\n",
    "The classifier did not do a good job of classifying our test data, as indicated by an accuracy score of 50%. There could be a number of reasons for the poor performance of our algorithm, most relevant of which is the tiny size of our training set. A sample size of 100 is very small when working with data such as science questions that can have a very high order of variation. With a bigger sample of labelled data, we might be able to achieve a better accuracy score. A bigger sample size will enable the classifier to better understand the corelations between the keywords in a question and it's label. For example, our sample did not have many instances of questions labelled 'Geology', therefore the classifier will have lower accuracy when trying to classify 'Geology' type questions. A larger dataset could correct this to some degree. \n",
    "\n",
    "To test the performance of our classifier on completely new data, I've created a test dataset from the student questions repository and labelled them by hand, just to have a value to measure the accuracy of classifier against. The classifier is already trained on the previous data and has no knowledge of the labels on the new data. It will read the questions in the new test dataset and try to predict the field of science the question belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Label (Manual)</th>\n",
       "      <th>Label (Classifier)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was there in space before the planets wer...</td>\n",
       "      <td>Astronomy</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why should the planets revolve around the sun?</td>\n",
       "      <td>Astronomy</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What if there are no trees, will we still get ...</td>\n",
       "      <td>Ecology</td>\n",
       "      <td>Ecology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solar panels always in black color. Why?</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Zoology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is wrong with eating junk food?</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does brain work? How does ideas strike there?</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the heart beat of humming bird?</td>\n",
       "      <td>Zoology</td>\n",
       "      <td>Zoology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is there inside earth?</td>\n",
       "      <td>Geology</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why this whole Universe has taken birth?</td>\n",
       "      <td>Astronomy</td>\n",
       "      <td>Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Why can't we live in space?</td>\n",
       "      <td>Astronomy</td>\n",
       "      <td>Zoology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions Label (Manual)  \\\n",
       "0  What was there in space before the planets wer...      Astronomy   \n",
       "1     Why should the planets revolve around the sun?      Astronomy   \n",
       "2  What if there are no trees, will we still get ...        Ecology   \n",
       "3           Solar panels always in black color. Why?      Chemistry   \n",
       "4               What is wrong with eating junk food?        Biology   \n",
       "5  How does brain work? How does ideas strike there?        Biology   \n",
       "6            What is the heart beat of humming bird?        Zoology   \n",
       "7                        What is there inside earth?        Geology   \n",
       "8           Why this whole Universe has taken birth?      Astronomy   \n",
       "9                        Why can't we live in space?      Astronomy   \n",
       "\n",
       "  Label (Classifier)  \n",
       "0          Astronomy  \n",
       "1          Astronomy  \n",
       "2            Ecology  \n",
       "3            Zoology  \n",
       "4            Biology  \n",
       "5            Biology  \n",
       "6            Zoology  \n",
       "7          Chemistry  \n",
       "8          Astronomy  \n",
       "9            Zoology  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the test dataset\n",
    "test_dataset = pd.read_csv('test_data.tsv', delimiter='\\t')\n",
    "\n",
    "# perform text pre-processing\n",
    "test_corpus = []\n",
    "\n",
    "for i in range(0, 130):\n",
    "    \n",
    "    question = re.sub('[^a-zA-Z]', ' ', test_dataset['Question'][i])\n",
    "    \n",
    "    question = question.lower()\n",
    "    \n",
    "    question = question.split()\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    cleaned_question = []\n",
    "    \n",
    "    for word in question:\n",
    "        \n",
    "        if not word in set(stopwords.words('english')):\n",
    "            cleaned_question.append(ps.stem(word))\n",
    "    \n",
    "    test_corpus.append(cleaned_question)\n",
    "\n",
    "# create a Bag of Words model for the test questions\n",
    "test_questions = cv.transform(test_corpus).toarray()\n",
    "\n",
    "# making the predictions using the classifier\n",
    "predicted_labels = classifier.predict(test_questions)\n",
    "\n",
    "# store the predicted labels for easier analysis\n",
    "with open('predictions.tsv', 'w') as file:\n",
    "    \n",
    "    file.write(\"Questions\\tLabel (Manual)\\tLabel (Classifier)\\n\")\n",
    "    \n",
    "    for i in range(0, 130):\n",
    "        file.write(test_dataset['Question'][i] + \"\\t\" + test_dataset['Field'][i] + \"\\t\" + predicted_labels[i] + \"\\n\")\n",
    "        \n",
    "# display the predictions for analysis and verification\n",
    "predictions = pd.read_csv('predictions.tsv', delimiter='\\t')\n",
    "\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The sample data was analyzed and categorized broadly into 'Comprehension' and 'Curiosity' classes, based on the nature of the question asked by the student. The questions were also labelled based on the branch of science that they belong to. A classifier was trained to classify the questions into their branches of science, and although the classifier performed poorly on our test data, I believe it can be improved by training it on a larger sample size and also by learning about and gaining exposure to Natural Language Processing methodologies and strategies to preprocess the data better, perform feature selection to make sure only relevant features of the data is selected to train a better classifier and most importantly, pick the best possible classification algorithm, or even tweak the algorithm to better fit the use-case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
